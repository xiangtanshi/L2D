'''
generate the template of shape, texture, background, store them in /data/counterfactual
shape templates: generated by cgn.u2net with images in train,valid,test dataset
texture templates: randomly select a few(8 to 10 for each class) images from the training set and crop texture from them
background templates: generated by cgn 
'''
import argparse
import os
from secrets import choice
import torch
import torch.nn as nn
import torchvision
from torch.utils.data import DataLoader
from tqdm import tqdm
from cgn import CGN
from u2net import U2NET
from cgn_class import *
import random

# save as grid image
def save_grid(im, path):
    torchvision.utils.save_image(im.detach().cpu(), path, normalize=True)


def toggle_grad(model, on_or_off):
    for param in model.parameters():
        param.requires_grad = on_or_off

def mkdir(path):
    folder = os.path.exists(path)
    if not folder:
        os.makedirs(path)

def get_args():

    parser = argparse.ArgumentParser(description='parameter setting for generating templates, mainly for loading the data.')
    parser.add_argument('datatype',default='animals',choices=['animals','vehicles'])
    parser.add_argument('settype',default='train',choices=['train','valid','test'])
    parser.add_argument('mechanism',default='shape')
    parser.add_argument('device',default=0,type=int)
    parser.add_argument('data_index',default=0,help='the data batch we operate on')

    return parser.parse_args()

def main(args):
    
    if args.mechanism == 'shape': 
        # extract shape for sets in animals and vehicles
        u2net_weights = './weights/u2net.pth'
        u2net = U2NET.initialize(u2net_weights).eval()
        toggle_grad(u2net, False)

        device = torch.device('cuda:{}'.format(args.device))
        u2net = u2net.to(device)

        
        loader = DataLoader(dataset=datas1[args.data_index], batch_size=1, shuffle=False, num_workers=1)    

        bar = tqdm(total=len(loader))   
        count = -1
        with torch.no_grad():
            for image,label in loader:   
                bar.update()
                count += 1
                image = image.to(device)
                m = u2net(image)
                # m = torch.clamp(m,0.001, 0.9999) - 0.001
                # m = m*10000
                m = torch.clamp(m, 0.0001, 0.9999).repeat(1, 3, 1, 1)
                save_grid(m, '/data/dengx/counterfactual/' + args.datatype + '/mask/' + args.settype + '/{}.jpg'.format(count))   
                
        bar.close()
    
    elif args.mechanism == 'texture':
        # foreground rearrange

        i = 0
        j = 0
        ani_loader = DataLoader(dataset=ani_ft,batch_size=1,shuffle=False)
        vel_loader = DataLoader(dataset=vel_ft,batch_size=1,shuffle=False)
        iter1 = iter(vel_loader)         
        iter2 = iter(ani_loader)
        cls1 = 8
        cls2 = 10

        for z in range(cls1):
            mkdir('/data/dengx/counterfactual/vehicles/foreground/texture/{}'.format(z))
        for z in range(cls2):
            mkdir('/data/dengx/counterfactual/animals/foreground/texture/{}'.format(z))


        for index in range(len(vel_loader)):       
            img1,_ = next(iter1)
            m = torch.zeros(1,3,256,256)
            for row in range(4):
                m[:,:,64*row:64*(row+1),0:64] = img1[:,:,:,32:96]
                m[:,:,64*row:64*(row+1),64:192] = img1
                m[:,:,64*row:64*(row+1),192:] = img1[:,:,:,32:96]

            save_grid(m, '/data/dengx/counterfactual/vehicles/foreground/texture/{}/{}.jpg'.format(i,j))                #
            if j == cls1-1:      
                i += 1
                j = 0
            else:
                j += 1

        i = 0
        j = 0

        for index in range(len(ani_loader)):       
            img1,_ = next(iter2)
            m = torch.zeros(1,3,256,256)
            for row in range(4):
                for col in range(4):
                    m[:,:,64*row:64*(row+1),64*col:64*(col+1)] = img1

            save_grid(m, '/data/dengx/counterfactual/animals/foreground/texture/{}/{}.jpg'.format(i,j))                #
            if j == cls2-1:      
                i += 1
                j = 0
            else:
                j += 1

    elif args.mechanism == 'background':
        # background template   
    
        list_background = range(100)
        list_target = list_background

        cgn = CGN(batch_sz=1, pretrained=False)
        device = torch.device('cuda:{}'.format(args.device))
        weights = torch.load('./weights/cgn.pth', map_location='cpu')
        cgn.load_state_dict(weights)
        cgn = cgn.to(device)
        bar = tqdm(total=len(list_target))

        for idx,clas in enumerate(list_target):

            ys = (clas,clas,clas)
            inp0,inp1,inp2 = cgn.get_inp(ys)
            bgs = cgn.f_bg(*inp2)
            bar.update()

            for i in range(len(bgs)):
                save_grid(bgs[i], '/data/dengx/counterfactual/background/{}.jpg'.format(idx))
        bar.close()

    else:
        print('nothing required, exit!')
    
    

if __name__ == '__main__':

    args = get_args()
    main(args)

    # python Cgn/generate_template.py --datatype animals --settype train --mechanism shape --device 0 --data_index 0
    # python Cgn/generate_template.py --datatype animals --settype valid --mechanism shape --device 0 --data_index 1
    # python Cgn/generate_template.py --datatype animals --settype test --mechanism shape --device 0 --data_index 2
    # python Cgn/generate_template.py --datatype vehicles --settype train --mechanism shape --device 0 --data_index 3
    # python Cgn/generate_template.py --datatype vehicles --settype valid --mechanism shape --device 0 --data_index 4
    # python Cgn/generate_template.py --datatype vehicles --settype test --mechanism shape --device 0 --data_index 5

    # python Cgn/generate_template.py --mechanism texture 
    # python Cgn/generate_template.py --mechanism background --device 0
